<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>Tor Project</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="A layout example that shows off a blog page with a list of posts.">
    <meta name="robots" content="noindex" />
    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/styles.css">

    <!--[if lte IE 8]>
      <link rel="stylesheet" href="css/blog-old-ie.css">
    <![endif]-->
    <!--[if lt IE 9]>
      <script src="http://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.js"></script>
    <![endif]-->
</head>
<body>

<body>
<div id="layout" class="pure-g">
    <div class="sidebar pure-u-1 pure-u-md-1-4">
        <div class="header">
            <a href="/"><img class="tor-logo" src="/assets/images/tor_logo.png" alt="Tor logo" /></a>
            <h1 class="brand-title">The Tor Project Blog</h1>
            <h2 class="brand-tagline">News and events from Tor</h2>

            <nav class="nav">
                <ul class="nav-list">
                    <li class="nav-item">
                        <a class="pure-button" href="/events/">Events</a>
                    </li>
                    <li class="nav-item">
                        <a class="pure-button" href="https://www.torproject.org/overview">About Tor</a>
                    </li>
                    <li class="nav-item">
                        <a class="pure-button" href="https://www.torproject.org/donate/donate">Donate</a>
                    </li>
                </ul>
            </nav>
        </div>
    </div>

    <div class="content pure-u-1 pure-u-md-3-4">
        <div>

            <!-- A wrapper for all the blog posts -->
<div class="posts">

  <h1 class="content-subhead">Recent Posts</h1>
  <div id="home">
    
      <section class="post">
        <header class="post-header">
          <h2 class="post-title"> <a href="/blog/tails-014-out">Tails 0.14 is out!</a></h2>
          <p class="post-meta">
              By <a class="post-author" href="#">tails</a> under
              
                <a class="post-category post-category-js" href="#">anonymous operating system</a>
              
                <a class="post-category post-category-js" href="#">tails</a>
              
                <a class="post-category post-category-js" href="#">tails releases</a>
               |
              12 Nov 2012
          </p>
        </header>
        <div class="post-description">
          <p>Tails, The Amnesic Incognito Live System, version 0.14, is out.</p>

<p>All users must upgrade as soon as possible.</p>

<p><a href="https://tails.boum.org/download/">Download it now.</a></p>

<p>Thank you, and congrats, to everyone who helped make this happen!</p>

<p><strong>Changes</strong></p>

<p>Notable user-visible changes include:</p>

<ul>
<li><p>Tor</p>

<ul>
<li>Upgrade to 0.2.3.24-rc</li>
<li>Enable <a href="https://tails.boum.org/contribute/design/stream_isolation/">stream isolation</a></li>
</ul></li>
<li><p>Iceweasel</p>

<ul>
<li>Upgrade iceweasel to 10.0.10esr-1+tails1, with anonymity enhancing patches from the TorBrowser applied</li>
<li>Fix Iceweasel&#39;s file associations. No more should you be suggested to open a PDF in the GIMP</li>
</ul></li>
<li><p>Hardware support</p>

<ul>
<li>Upgrade Linux to 3.2.32</li>
<li>Support more than 4GB of RAM</li>
<li>Support more than one CPU core</li>
</ul></li>
<li><p>Miscellaneous</p>

<ul>
<li>Mostly fix memory wiping at shutdown</li>
<li>gpgApplet can now handle public-key cryptography</li>
<li>Add a persistence preset for NetworkManager connections</li>
<li>Better support setting up persistence on large USB sticks</li>
<li>Make boot faster by fixing a read-ahead bug</li>
<li>Make shutdown faster by disabling useless scripts</li>
</ul></li>
<li><p>Localization</p>

<ul>
<li>Custom software is now translated in many more languages</li>
<li>Add Japanese input system</li>
</ul></li>
</ul>

<p>Plus the usual bunch of bug reports and minor improvements.</p>

<p>See the <a href="http://git.immerda.ch/?p=amnesia.git;a=blob_plain;f=debian/changelog;hb=refs/tags/0.14">online
Changelog</a> for technical details.</p>

<p>Don&#39;t hesitate to <a href="https://tails.boum.org/support/">get in touch with us</a>.</p>

        </div>
      </section>
    
      <section class="post">
        <header class="post-header">
          <h2 class="post-title"> <a href="/blog/top-changes-tor-2004-design-paper-part-3">Top changes in Tor since the 2004 design paper (Part 3)</a></h2>
          <p class="post-meta">
              By <a class="post-author" href="#">sjmurdoch</a> under
               |
              01 Nov 2012
          </p>
        </header>
        <div class="post-description">
          <p>In this third and final installment of Nick Mathewson and Steven Murdoch&#39;s blog series (previously <a href="https://blog.torproject.org/blog/top-changes-tor-2004-design-paper-part-1">part 1</a> and <a href="https://blog.torproject.org/blog/top-changes-tor-2004-design-paper-part-2">part 2</a>) we discuss how Tor has made its traffic harder to fingerprint, as well as usability and security improvements to how users interact with Tor.</p>

<h2>9. Link protocol TLS, renegotiation</h2>

<p>Tor&#39;s original (version 1) TLS handshake was fairly straightforward. The client said that it supported a sensible set of cryptographic algorithms and parameters (ciphersuites, in TLS terminology) and the server selected one. If one side wanted to prove to the other that it was a Tor node, it would send a two-element certificate chain signed by the key published in the Tor directory.</p>

<p>This approach met all the security properties envisaged at the time the 2004 design paper was written, but Tor&#39;s increasing use in censorship resistance changed the requirements â€“ Tor&#39;s protocol signature also had to look like that of HTTPS web traffic, to prevent censors using deep-packet-inspection to detect and block Tor.</p>

<p>It turned out that Tor&#39;s original design looked very different from HTTPS. Firstly, web browsers offer a wide range of ciphersuites which Tor cannot use, such as those using RC4 (due to the narrow security margins) and RSA key exchange (due to lack of <a href="https://en.wikipedia.org/wiki/Perfect_forward_secrecy">forward secrecy</a>). Secondly, in HTTPS web traffic, the client seldom offers a certificate, and the server usually offers a one-element certificate chain, whereas in Tor node-to-node communication both sides offer a two-element certificate chain.</p>

<p>Therefore <a href="https://gitweb.torproject.org/torspec.git/blob/HEAD:/proposals/124-tls-certificates.txt">proposal 124</a>, later superseded by <a href="https://gitweb.torproject.org/torspec.git/blob/HEAD:/proposals/130-v2-conn-protocol.txt">proposal 130</a>, tried to resolve the situation and the resulting version 2 connection protocol was implemented in Tor 0.2.0.20-rc. Here, the client presents a large selection of ciphersuites (including some it doesn&#39;t actually support), selected to appear similar to that of a web browser. The server then chooses one which is suitable for use in Tor, but if the server chooses one which is not adequately secure, the client will pull down the connection.</p>

<p>To make the certificate part of the handshake look closer to HTTPS, the client sends no certificate, and the server sends a one-element dummy certificate chain. The certificate offered by the server is designed to not contain distinctive strings which could be used for blocking (version 1 certificates used &quot;Tor&quot; or &quot;TOR&quot; as the organization name). Once the handshake is complete, Tor then restarts the handshake (via TLS renegotiation), but now encrypted under the keys established in the first handshake, and sends the two-element certificate chains as before.</p>

<p>This improves the situation for anti-blocking considerably, although more could still be done. In particular, the fact that renegotiation is occurring is not hidden from an observer because the type of TLS messages (known as records) is not encrypted in TLS, and renegotiation records are of a different type from data records. Therefore version 3 of the connection protocol, described in <a href="https://gitweb.torproject.org/torspec.git/blob/HEAD:/proposals/176-revising-handshake.txt">proposal 176</a> and implemented in Tor 0.2.3.6-alpha, moves the second stage of the handshake into data records, binding the inner to the outer handshake through sharing some key material.</p>

<h2>10. Rise and fall of .exit</h2>

<p>In Tor 0.0.9rc5, Tor had the .exit feature added. Here, if the user requested <em>domain</em>.<em>nickname</em>.exit then Tor would make a connection to <em>domain</em> using the Tor node called <em>nickname</em> as the last hop (if possible). This was a convenient feature for exploring how the Internet looked from different locations, but it also raised some security concerns.</p>

<p>In particular, a malicious website could embed an image with a .exit hostname, forcing the Tor client to select an attacker-controlled exit node. Then, if the user also chooses an attacker-controlled entry node the circuit could be de-anonymized. This strategy increases the probability of a successful attack from about (M/N)<sup>2</sup> to M/N (where M is the amount of attacker-controlled network resource and N is the total network resource).</p>

<p>Therefore, in Tor 0.2.2.1-alpha, .exit notation was disabled by default. In Tor 0.2.3.17-beta an exception was made, allowing .exit notation when it is specified in the configuration file or by a controller. These sources are assumed to be safe, and by combining the .exit notation with the MapAddress option it is possible for the client to always contact some domain names via a particular exit node. This is useful when a service is running on the same machine as a Tor node, as then the user can choose for circuits to never leave the Tor network.</p>

<h2>11. Controller protocol</h2>

<p>Tor has always had a minimalist user interface â€“ it can be configured on the command line or a configuration file and sends output to a log file. This is fine for advanced users, but most users will prefer a GUI. Building a GUI into Tor would be difficult, and would force certain choices (e.g. GUI toolkit) to be made which might not suit all users and all platforms. Therefore the approach taken by Tor in 0.0.9pre5 is to build an interface for other programs â€“ the control protocol â€“ to communicate with the Tor daemon, extracting information to display on the GUI and changing the Tor configuration based on user actions.</p>

<p>The control protocol has also proven useful to researchers experimenting with Tor. Initially the functionality exposed in the control protocol was simply that exposed by the configuration file and log files. Providing status information in a specified and machine-readable format made the task of monitoring and controlling Tor easier. Later, functionality was added to the control protocol which should not be exposed to ordinary Tor users but is useful to researchers, such as allowing controllers to arbitrarily control the path selection process (added in 0.1.0.1-rc).</p>

<p>In 0.1.1.1-alpha the protocol was changed to version 1, which used ASCII rather than binary commands to make it easier to write and debug controllers as well as allow advanced users to telnet into the control port and manually type commands.</p>

<h2>12. Torbutton</h2>

<p>The 2004 design paper stated that Tor explicitly did not make any attempt to scrub application data which might contain identifying information. By adopting the near universal SOCKS protocol, almost any application could send its traffic over Tor, but there was no guarantee it would be safe to do so. This is in contrast to the the predecessors to Tor from the Onion Routing project which required an &quot;application proxy&quot; to be written for each protocol carried by Tor. These proxies greatly increased the cost for supporting each additional application.</p>

<p>Still, there was clear need for a place to perform the protocol scrubbing, and so Tor recommended that <a href="http://www.privoxy.org/">Privoxy</a> take the place of an application proxy for HTTP. However, the disadvantages of this approach gradually became clear, in particular Privoxy could not inspect or modify HTTPS traffic and so malicious websites could send their tracking code over HTTPS and avoid scrubbing.</p>

<p>Therefore, more and more of the scrubbing was performed by a Firefox add-on, <a href="https://www.torproject.org/torbutton/">Torbutton</a>, which also could turn Tor on and off â€“ hence the name. Torbutton had full access to content regardless of whether it was HTTP or HTTPS and could also disable features of Firefox which were bad for privacy. A proxy was still needed though, because Firefox&#39;s SOCKS support handled high-latency connections badly, so the lighter-weight <a href="http://www.pps.univ-paris-diderot.fr/%7Ejch/software/polipo/">Polipo</a> was adopted instead.</p>

<h2>13. Tor Browser Bundle</h2>

<p>Now to use Tor, most users would need to download and install Tor, Firefox, Torbutton and Polipo, probably along with a GUI controller such as <a href="https://www.torproject.org/projects/vidalia.html.en">Vidalia</a>. This was inconvenient, especially for customers of Internet cafes who could not install software on the computer they were using. So the Tor Browser Bundle was created which included all this software, pre-configured to be run from a USB drive.</p>

<p>This was far easier to use than the previous way to install Tor, and eventually became the default. It had the added advantage that we could modify the browser to include patches which made Polipo unnecessary and to fix some privacy problems which could not be solved from within a Firefox add-on. It was also safer for users because now Torbutton could not be disabled, meaning that the user had different web browsers for anonymous and non-anonymous browsing and were less likely to muddle up the two.</p>

        </div>
      </section>
    
      <section class="post">
        <header class="post-header">
          <h2 class="post-title"> <a href="/blog/new-tor-browser-bundles-and-alpha-bundles-0">New Tor Browser Bundles and alpha bundles</a></h2>
          <p class="post-meta">
              By <a class="post-author" href="#">erinn</a> under
              
                <a class="post-category post-category-js" href="#">firefox updates</a>
              
                <a class="post-category post-category-js" href="#">release candidate</a>
              
                <a class="post-category post-category-js" href="#">tbb</a>
              
                <a class="post-category post-category-js" href="#">tor browser bundle</a>
               |
              30 Oct 2012
          </p>
        </header>
        <div class="post-description">
          <p>All of the Tor Browser Bundles have been updated with the latest Firefox 10.0.10esr release and all of the alpha packages, including the alpha Tor Browser Bundles, have been updated with the latest release of Tor 0.2.3.24-rc.</p>

<p><a href="https://www.torproject.org/download" title="https://www.torproject.org/download">https://www.torproject.org/download</a></p>

<p>Further notes about Tor Browser Bundle updates:</p>

<p><strong>Tor Browser Bundle (2.2.39-5)</strong></p>

<ul>
<li>Update Firefox to 10.0.10esr</li>
<li>Update NoScript to 2.5.9</li>
</ul>

<p><strong>Tor Browser Bundle (2.3.24-alpha-1)</strong></p>

<ul>
<li>Update Tor to 0.2.3.24-rc</li>
<li>Update Firefox to 10.0.10esr</li>
<li>Update NoScript to 2.5.9</li>
<li>Update HTTPS Everywhere to 4.0development.2</li>
</ul>

        </div>
      </section>
    
      <section class="post">
        <header class="post-header">
          <h2 class="post-title"> <a href="/blog/new-tor-browser-bundles-and-alpha-bundles">New Tor Browser Bundles and alpha bundles</a></h2>
          <p class="post-meta">
              By <a class="post-author" href="#">erinn</a> under
              
                <a class="post-category post-category-js" href="#">firefox updates</a>
              
                <a class="post-category post-category-js" href="#">release candidate</a>
              
                <a class="post-category post-category-js" href="#">tbb</a>
              
                <a class="post-category post-category-js" href="#">tor browser bundle</a>
               |
              23 Oct 2012
          </p>
        </header>
        <div class="post-description">
          <p>The stable Tor Browser Bundles have been updated to fix a crash bug that existed in the previous version. If you were experiencing problems, please update and <a href="https://trac.torproject.org">let us know</a> if you have any further problems.</p>

<p>All alpha bundles have also been updated to Tor 0.2.3.23-rc. We&#39;ve downgraded the Firefox version in the alpha Tor Browser Bundles to 10.0.9esr and will continue to keep the same version of Firefox in both bundles for the foreseeable future. In addition to that, the Linux and OS X versions have automatic port selection re-enabled, so those of you who were experiencing trouble running a concurrent system Tor on those systems should no longer have any issues.</p>

<p>All users who were using Tor 0.2.3.22-rc are strongly encouraged to upgrade.</p>

<p><a href="https://www.torproject.org/download" title="https://www.torproject.org/download">https://www.torproject.org/download</a></p>

<p>Further notes about Tor Browser Bundle updates:</p>

<p><strong>Tor Browser Bundle (2.2.39-4)</strong></p>

<ul>
<li>Update Firefox patches to prevent crashing (closes: #7128)</li>
<li>Update HTTPS Everywhere to 3.0.2</li>
<li>Update NoScript to 2.5.8</li>
</ul>

<p><strong>Tor Browser Bundle (2.3.23-alpha-1)</strong></p>

<ul>
<li>Update Tor to 0.2.3.23-rc</li>
<li>Update Firefox to 10.0.9esr</li>
<li>Update HTTPS Everywhere to 4.0development.1</li>
<li>Update NoScript to 2.5.8</li>
<li>Re-enable automatic Control and SOCKS port selection on Linux and OSX</li>
</ul>

        </div>
      </section>
    
      <section class="post">
        <header class="post-header">
          <h2 class="post-title"> <a href="/blog/top-changes-tor-2004-design-paper-part-2">Top changes in Tor since the 2004 design paper (Part 2)</a></h2>
          <p class="post-meta">
              By <a class="post-author" href="#">nickm</a> under
               |
              22 Oct 2012
          </p>
        </header>
        <div class="post-description">
          <p>This is part 2 of Nick Mathewson and Steven Murdoch&#39;s series on what has changed in Tor&#39;s design since the original design paper in 2004. <a href="https://blog.torproject.org/blog/top-changes-tor-2004-design-paper-part-1">Part one is back over here.</a></p>

<p>In this installment, we cover changes in how we pick and use nodes in our circuits, and general anticensorship features.</p>

<h2>5. Guard nodes</h2>

<p>We assume, based on a fairly large body of research, that if an attacker controls or monitors the first hop and last hop of a circuit, then the attacker can de-anonymize the user by correlating timing and volume information. Many of the security improvements to path selection discussed in this post concentrate on reducing the probability that an attacker can be in this position, but no reasonably efficient proposal can eliminate the possibility.</p>

<p>Therefore, each time a user creates a circuit, there is a small chance that the circuit will be compromised. However, most users create a large number of Tor circuits, so with the original path selection algorithm, these small chances would build up into a potentially large chance that at least one of their circuits will be compromised.</p>

<p>To help improve this situation, in Tor 0.1.1.2-alpha, the guard node feature was implemented (initially called &quot;helper nodes&quot;, invented by <a href="http://people.cs.umass.edu/%7Emwright/papers/wright-passive.pdf">Wright, Adler, Levine, and Shields</a> and proposed for use in Tor by <a href="http://www.onion-router.net/Publications/locating-hidden-servers.pdf">Ã˜verlier and Syverson</a>). In Tor 0.1.1.11-alpha it was enabled by default. Now, the Tor client picks a few Tor nodes as its &quot;guards&quot;, and uses one of them as the first hop for all circuits (as long as those nodes remain operational).</p>

<p>This doesn&#39;t affect the probability that the first circuit is compromised, but it does mean that if the guard nodes chosen by a user are not attacker-controlled all their future circuits will be safe. On the other hand, users who choose attacker-controlled guards will have about M/N of their circuits compromised, where M is the amount of attacker-controlled network resource and N is the total network resource. Without guard nodes every circuit has a (M/N)<sup>2</sup> probability of being compromised.</p>

<p>Essentially, the guard node approach recognises that some circuits are going to be compromised, but it&#39;s better to increase your probability of having <strong>no</strong> compromised circuits at the expense of also increasing the proportion of your circuits that will be compromised if any of them are. This is because compromising a fraction of a user&#39;s circuitsâ€”sometimes even just oneâ€”can be enough to compromise a user&#39;s anonymity. For users who have good guard nodes, the situation is much better, and for users with bad guard nodes the situation is not much worse than before.</p>

<h2>6. Bridges, censorship resistance, and pluggable transports</h2>

<p>While Tor was originally designed as an anonymous communication system, more and more users need to circumvent censorship rather than to just preserve their privacy. The two goals are closely linked â€“ to prevent a censor from blocking access to certain websites, it is necessary to hide where a user is connecting to. Also, many censored Internet users live in repressive regimes which might punish people who access banned websites, so here anonymity is also of critical importance.</p>

<p>However, anonymity is not enough. Censors can&#39;t block access to certain websites browsed over Tor, but it was easy for censors to block access to the whole of the Tor network in the original design. This is because there were a handful of directory authorities which users needed to connect to before they could discover the addresses of Tor nodes, and indeed some censors blocked the directory authorities. Even if users could discover the current list of Tor nodes, censors also blocked the IP addresses of all Tor nodes too.</p>

<p>Therefore, the <a href="https://svn.torproject.org/svn/projects/design-paper/blocking.html">Tor censorship resistance design</a> introduced bridges â€“ special Tor nodes which were not published in the directory, and could be used as entry points to the network (both for downloading the directory and also for building circuits). Users need to find out about these somehow, so the bridge authority collects the IP addresses and gives them out via email, on the web, and via personal contacts, so as to make it difficult for the censor to enumerate them all.</p>

<p>That&#39;s not enough to provide censorship resistance though. Preventing the censor from knowing all the IP addresses they need to block to block access to the Tor network will be enough to defeat some censors. But others have the capability to block not only by IP address but also by content (deep packet inspection). Some censors have tried to do this already and Tor has, in response, gradually changed its TLS handshake to better imitate web browsers.</p>

<p>Impersonating web browsers is difficult, and even if Tor perfectly impersonated one, some censors could just block encrypted web browsing (like Iran did, for some time). So it would be better if Tor could impersonate multiple protocols. Even better would be if other people could contribute to this goal, rather than the Tor developers being a bottleneck. This is the motivation of the <a href="https://gitweb.torproject.org/torspec.git/blob/HEAD:/proposals/180-pluggable-transport.txt">pluggable transports</a> design which allows Tor to manage an external program which transforms Tor traffic into some hard-to-fingerprint obfuscation.</p>

<h2>7. Changes and complexities in our path selection algorithms</h2>

<p>The original Tor paper never specified how clients should pick which nodes to use when constructing a circuit through the network. This question has proven unexpectedly complex.</p>

<h3>Weighting node selection by bandwidth</h3>

<p>The simplest possible approach to path construction, which we used in the earliest versions of Tor, is simply to pick uniformly at random from all advertised nodes that could be used for a given position in the path. But this approach creates terrible bandwidth bottlenecks: a server that would allow 10x as many bytes per second as another would still get the same number of circuits constructed through it.</p>

<p>Therefore, Tor 0.0.8rc1 started to have clients weight their choice of nodes by servers&#39; advertised bandwidths, so that a server with 10x as much bandwidth would get 10x as many circuits, and therefore (probabilistically) 10x as much of the traffic.</p>

<p>(In the original paper, we imagined that we might take Morphmix&#39;s approach, and divide nodes into &quot;bandwidth classes&quot;, such that clients would choose only from among nodes having at least the same approximate bandwidth as the clients. This may be a good design for peer-to-peer anonymity networks, but it doesn&#39;t seem to work for the Tor network: the most useful high-capacity nodes have more capacity than nearly any typical client.)</p>

<p>Later, it proved that weighting by bandwidth was also suboptimal, because of nonuniformity in path selection rules. Consider that if node A is suitable for use at any point in a circuit, but node B is suitable only as the middle node, then node A will be considered for use three times as often as B. If the two nodes have equal bandwidth, node A will be chosen three times as often, leading to it being overloaded in comparison with B. So eventually, in Tor 0.2.2.10-alpha, we moved to a more sophisticated approach, where nodes are chosen proportionally to their bandwidth, as weighted by an algorithm to optimize load-balancing between nodes of different capabilities.</p>

<h3>Bandwidth authorities</h3>

<p>Of course, once you choose nodes with unequal probability, you open the possibility of an attacker trying to see a disproportionate number of circuits -- not by running an extra-high number of nodes -- but by claiming to have a very large bandwidth.</p>

<p>For a while, we tried to limit the impact of this attack by limiting the maximum bandwidth that a client would believe, so that a single rogue node couldn&#39;t just claim to have infinite bandwidth.</p>

<p>In 0.2.1.17-rc, clients switched from using bandwidth values advertised by nodes themselves to using values published in the network status consensus document. A subset of the authorities measure and vote on nodes&#39; observed bandwidth, to prevent misbehaving nodes from claiming (intentionally or accidentally) to have too much capacity.</p>

<h3>Avoiding duplicate families in a single circuit</h3>

<p>As mentioned above, if the first and last node in a circuit are controlled by an adversary, they can use traffic correlation attacks to notice that the traffic entering the network at the first hop matches traffic leaving the circuit at the last hop, and thereby trace a client&#39;s activity with high probability. Research on preventing this attack has not yet come up with any affordable, effective defense suitable for use in a low-latency anonymity network. Therefore, the most promising mitigation strategies seem to involve lowering the attacker&#39;s chances of controlling both ends of a circuit.</p>

<p>To this end, clients do not use any two nodes in a circuit whose IP addresses are in the same /16 â€“ when we designed the network, it was marginally more difficult to acquire a large number of disparate addresses than it was to get a large number of concentrated addresses. (Roger and Nick may have been influenced by their undergraduacy at MIT, where their dormitory occupied the entirety of 18.244.0.0/16.) This approach is imperfect, but possibly better than nothing.</p>

<p>To allow honest node operators to run more than one server without inadvertently giving themselves the chance to see more traffic than they should, we also allow nodes to declare themselves to be members of the same &quot;family&quot;, such that a client won&#39;t use two nodes in the same family in the same circuit. (Clients only believe mutual family declarations, so that an adversary can&#39;t capture routes by having his nodes claim unilaterally to be in a family with every node the adversary <em>doesn&#39;t</em> control.)</p>

<h2>8. Stream isolation</h2>

<p>Building a circuit is fairly expensive (in terms of computation and bandwidth) for the network, and the setup takes time, so the Tor client tries to re-use existing circuits if possible, by sending multiple TCP streams down them. Streams which share a circuit are linkable, because the exit node can tell that they have the same circuit ID. If the user sends some information on one stream which gives their identity away, the other streams on the same circuit will be de-anonymized.</p>

<p>To reduce the risk of this occurring, Tor will not re-use a circuit which the client first used more than 10 minutes ago. Users can also use their Tor controller to send the &quot;NEWNYM&quot; signal, preventing any old circuits being used for new streams. As long as users don&#39;t mix anonymous and non-anoymous tasks at the same time, this form of circuit re-use is probably a good tradeoff.</p>

<p>However, <a href="http://hal.inria.fr/docs/00/47/15/56/PDF/TorBT.pdf">Manils et al.</a> discovered that some Tor users simultaneously ran BitTorrent over the same Tor client as they did web browsing. Running BitTorrent over Tor is a bad idea because the network can&#39;t handle the load, and because BitTorrent packets include the user&#39;s real IP address in the payload, so it isn&#39;t anonymous. But running BitTorrent while doing anonymous web browsing is an especially bad idea. An exit node can find the user&#39;s IP address in the BitTorrent payload then trivially de-anonymize all streams sharing the circuit.</p>

<p>Running BitTorrent over Tor is still strongly discouraged, but this paper did illustrate some potential problems with circuit reuse so <a href="https://gitweb.torproject.org/torspec.git/blob/master:/proposals/171-separate-streams.txt">proposal 171</a> was written, and implemented in Tor 0.2.3.3-alpha, to help isolate streams which shouldn&#39;t share the same circuit. By default streams which were initiated by different clients, which came from SOCKS connections with different authentication credentials, or which came to a different SOCKS port on the Tor client, are separated. In this way, a user can isolate applications by either setting up multiple SOCKS ports on Tor and using one per application, or by setting up a single SOCKS port but using different username/passwords for each application. Tor can also be configured to isolate streams based on destination address and/or port.</p>

        </div>
      </section>
    

     <!-- Pagination links -->
    <div class="pagination">
      
        <a href="/blog/page43" class="previous">Previous</a>
      
      <span class="page_number ">Page: 44 of 134</span>
      
        <a href="/blog/page45" class="next">Next</a>
      
    </div>
  </div>

</div>


            <div class="footer">
                <div class="pure-menu pure-menu-horizontal pure-menu-open">
                    <ul>
                        <li><a href="http://purecss.io/">About</a></li>
                        <li><a href="http://twitter.com/yuilibrary/">Twitter</a></li>
                        <li><a href="http://github.com/yahoo/pure/">GitHub</a></li>
                    </ul>
                </div>
            </div>
        </div>
    </div>
</div>
</body>
</html>
